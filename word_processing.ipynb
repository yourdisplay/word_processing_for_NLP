{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Копия блокнота \"data_fusion.ipynb\"","provenance":[{"file_id":"1QR0y080ET5gy2YPI4fTculUmXGFRIquO","timestamp":1614930911522}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"gLZIMCwOHzpK"},"source":["## Простейшая предобработка текста (удаление цифр, пунктуации)"]},{"cell_type":"code","metadata":{"id":"WX1atDw5Z7vw","executionInfo":{"status":"ok","timestamp":1615536074922,"user_tz":-300,"elapsed":760,"user":{"displayName":"Rishat Galinurov","photoUrl":"","userId":"16828873374745891840"}}},"source":["import re\r\n","\r\n","# добавим пробелы перед и после знаков препинания, \r\n","# чтобы при дальнейшем удалении пунктуации отдельные слова не сливались в одно\r\n","def add_space(text):\r\n","    new_text = ''\r\n","    for i in text:\r\n","        if i in '!\"#$&\\'()%*+,.:;<=>?@[\\\\]^_`{|}~':\r\n","            new_text += ' ' + i + ' '\r\n","        else:\r\n","            new_text += i\r\n","    return new_text\r\n","\r\n","# удалим все числа (хотя возможно они были бы полезны)\r\n","def remove_numbers(text):\r\n","    result = re.sub(r'\\d+', '', text)\r\n","    return result\r\n","\r\n","# удалим знаки препинания\r\n","def remove_punctuation(text):\r\n","    translator = str.maketrans('', '', '!\"#$&%*\\'()+,.:;<=>?@[\\\\]^_`{|}~')\r\n","    return text.translate(translator)\r\n","\r\n","# избавимся от лишних пробелов\r\n","def remove_whitespace(text):\r\n","    return  \" \".join(text.split())\r\n","\r\n","def preprocessing_text(text_feature):\r\n","    text_feature = text_feature.apply(add_space)\r\n","    text_feature = text_feature.apply(lambda x: x.lower()) \r\n","    text_feature = text_feature.apply(remove_numbers)\r\n","    text_feature = text_feature.apply(remove_punctuation)\r\n","    text_feature = text_feature.apply(remove_whitespace)\r\n","    return text_feature"],"execution_count":117,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DZ9QnusIVHMn"},"source":["## Преобразование слов в начальную форму\n","с помощью pymorfy2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jh9Qeuy9Vl5o","executionInfo":{"status":"ok","timestamp":1615523485612,"user_tz":-300,"elapsed":6129,"user":{"displayName":"Rishat Galinurov","photoUrl":"","userId":"16828873374745891840"}},"outputId":"f10a4ab6-1044-461c-8b22-0f872cb48550"},"source":["!pip install pymorphy2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pymorphy2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n","\r\u001b[K     |██████                          | 10kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 18.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40kB 14.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 4.9MB/s \n","\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n","Collecting dawg-python>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n","Collecting pymorphy2-dicts-ru<3.0,>=2.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n","\u001b[K     |████████████████████████████████| 8.2MB 14.5MB/s \n","\u001b[?25hInstalling collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2\n","Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C0pVHNLLVTBl"},"source":["import pymorphy2\r\n","import os\r\n","#преобразование в нач.форму слов с использованием pyMorfy2\r\n","def f_tokenizer(s):\r\n","    morph = pymorphy2.MorphAnalyzer()\r\n","    j1 = ' '.join(map(str, s))\r\n","    j2 = j1.split()       \r\n","    f = []\r\n","    for word in j2:\r\n","        m = morph.parse(word)\r\n"," #       m = [morph.parse(word) for word in j]\r\n","        if len(m) != 2:\r\n","          wrd = m[0]\r\n","          if wrd.tag.POS not in ('NUMR','PREP','CONJ','PRCL','INTJ'):\r\n","              f.append(wrd.normal_form)\r\n","    return f"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y3J-Lu-bXENR"},"source":["marked_data1 = f_tokenizer(marked_data['item_name'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["## Стеммер Портера - алгоритм не использует баз основ слов, а лишь, применяя последовательно ряд правил, отсекает окончания и суффиксы, основываясь на особенностях языка, в связи с чем работает быстро, но не всегда безошибочно."]},{"cell_type":"code","metadata":{"id":"PqKku-ku-Nrz"},"source":["class Porter:\r\n","\tPERFECTIVEGROUND =  re.compile(u\"((ив|ивши|ившись|ыв|ывши|ывшись)|((?<=[ая])(в|вши|вшись)))$\")\r\n","\tREFLEXIVE = re.compile(u\"(с[яь])$\")\r\n","\tADJECTIVE = re.compile(u\"(ее|ие|ые|ое|ими|ыми|ей|ий|ый|ой|ем|им|ым|ом|его|ого|ему|ому|их|ых|ую|юю|ая|яя|ою|ею)$\")\r\n","\tPARTICIPLE = re.compile(u\"((ивш|ывш|ующ)|((?<=[ая])(ем|нн|вш|ющ|щ)))$\")\r\n","\tVERB = re.compile(u\"((ила|ыла|ена|ейте|уйте|ите|или|ыли|ей|уй|ил|ыл|им|ым|ен|ило|ыло|ено|ят|ует|уют|ит|ыт|ены|ить|ыть|ишь|ую|ю)|((?<=[ая])(ла|на|ете|йте|ли|й|л|ем|н|ло|но|ет|ют|ны|ть|ешь|нно)))$\")\r\n","\tNOUN = re.compile(u\"(а|ев|ов|ие|ье|е|иями|ями|ами|еи|ии|и|ией|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я)$\")\r\n","\tRVRE = re.compile(u\"^(.*?[аеиоуыэюя])(.*)$\")\r\n","\tDERIVATIONAL = re.compile(u\".*[^аеиоуыэюя]+[аеиоуыэюя].*ость?$\")\r\n","\tDER = re.compile(u\"ость?$\")\r\n","\tSUPERLATIVE = re.compile(u\"(ейше|ейш)$\")\r\n","\tI = re.compile(u\"и$\")\r\n","\tP = re.compile(u\"ь$\")\r\n","\tNN = re.compile(u\"нн$\")\r\n","\r\n","\tdef stem(word):\r\n","\t\tword = word.lower()\r\n","\t\tword = word.replace(u'ё', u'е')\r\n","\t\tm = re.match(Porter.RVRE, word)\r\n","\t\tif m and m.groups():\r\n","\t\t\tpre = m.group(1)\r\n","\t\t\trv = m.group(2)\r\n","\t\t\ttemp = Porter.PERFECTIVEGROUND.sub('', rv, 1)\r\n","\t\t\tif temp == rv:\r\n","\t\t\t\trv = Porter.REFLEXIVE.sub('', rv, 1)\r\n","\t\t\t\ttemp = Porter.ADJECTIVE.sub('', rv, 1)\r\n","\t\t\t\tif temp != rv:\r\n","\t\t\t\t\trv = temp\r\n","\t\t\t\t\trv = Porter.PARTICIPLE.sub('', rv, 1)\r\n","\t\t\t\telse:\r\n","\t\t\t\t\ttemp = Porter.VERB.sub('', rv, 1)\r\n","\t\t\t\t\tif temp == rv:\r\n","\t\t\t\t\t\trv = Porter.NOUN.sub('', rv, 1)\r\n","\t\t\t\t\telse:\r\n","\t\t\t\t\t\trv = temp\r\n","\t\t\telse:\r\n","\t\t\t\trv = temp\r\n","\t\t\t\r\n","\t\t\trv = Porter.I.sub('', rv, 1)\r\n","\r\n","\t\t\tif re.match(Porter.DERIVATIONAL, rv):\r\n","\t\t\t\trv = Porter.DER.sub('', rv, 1)\r\n","\r\n","\t\t\ttemp = Porter.P.sub('', rv, 1)\r\n","\t\t\tif temp == rv:\r\n","\t\t\t\trv = Porter.SUPERLATIVE.sub('', rv, 1)\r\n","\t\t\t\trv = Porter.NN.sub(u'н', rv, 1)\r\n","\t\t\telse:\r\n","\t\t\t\trv = temp\r\n","\t\t\tword = pre+rv\r\n","\t\treturn word\r\n","\tstem=staticmethod(stem)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"2SO4vgh1-OfP","executionInfo":{"status":"ok","timestamp":1615528049005,"user_tz":-300,"elapsed":800,"user":{"displayName":"Rishat Galinurov","photoUrl":"","userId":"16828873374745891840"}},"outputId":"af2d132e-7b24-4926-804e-232d531e0d4a"},"source":["Porter.stem(u'устойчивость')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'устойчив'"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBBV-T43_xJx","executionInfo":{"status":"ok","timestamp":1615528527584,"user_tz":-300,"elapsed":776,"user":{"displayName":"Rishat Galinurov","photoUrl":"","userId":"16828873374745891840"}},"outputId":"e472f180-117e-4257-f49b-e3f179cf8b2b"},"source":["from nltk.corpus import stopwords\r\n","import nltk\r\n","nltk.download('stopwords')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"9aTQWEyI79jP","executionInfo":{"status":"ok","timestamp":1615536019667,"user_tz":-300,"elapsed":808,"user":{"displayName":"Rishat Galinurov","photoUrl":"","userId":"16828873374745891840"}}},"source":["def preprocessor(text):\r\n","    text = re.sub('<[^>]*>', '', text)\r\n","    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\r\n","    text = (\r\n","        re.sub('[\\W]+', ' ', text.lower()) +\r\n","        ' '.join(emoticons).replace('-', '')\r\n","    )\r\n","    return text\r\n","\r\n","\r\n","def tokenizer(text):\r\n","    return text.split()\r\n","\r\n","\r\n","def tokenizer_porter(text):\r\n","    return [Porter.stem(word) for word in text.split()]\r\n","\r\n","\r\n","def tokenizer_streaming(text):\r\n","    text = preprocessor(text)\r\n","    stop = stopwords.words('russian')\r\n","    tokenized = [w for w in text.split() if w not in stop]\r\n","    return tokenized\r\n","\r\n","def tokenizer_streaming_porter(text):\r\n","    text = preprocessor(text)\r\n","    stop = stopwords.words('russian')\r\n","    tokenized = [Porter.stem(word) for word in text.split() if word not in stop]\r\n","    return tokenized\r\n","\r\n","def preprocessing(text_feature):\r\n","    text_feature = text_feature.apply(preprocessor)\r\n","    #text_feature = text_feature.apply(tokenizer) \r\n","    #text_feature = text_feature.apply(tokenizer_porter)\r\n","    text_feature = text_feature.apply(tokenizer_streaming) \r\n","    return text_feature\r\n","\r\n"],"execution_count":114,"outputs":[]}]}